arch: "x86_64"
serial:
    active: true
    port: "/dev/ttyUSB0"
    baudrate: 57600
    timeout: 1 # seconds
depth_scale: 0.00025
# Mesh creation for ORGANIZED point clouds
mesh:
    use_cuda: false # use GPU CUDA acceleration for mesh smoothing
    stride: 2 # skip rows/columns
    filter:
        loops_laplacian: 2 # how many iterations
        _lambda: 1.0 # weight factor for laplacian update
        kernel_size: 3 # only changes for laplacian
        loops_bilateral: 1 # how many iterations
        sigma_length: 0.3 # std of distance between triangles centroids
        sigma_angle: 0.2 # std of distance between triangles normals
# mesh smoothing for INTEGRATED meshes
mesh_integrated:
    filter:
        loops_bilateral: 3 # how many iterations
        sigma_length: 0.2 # std of distance between triangles centroids
        sigma_angle: 0.2 # std of distance between triangles normals
polylidar: # Parameters we send to polylidar. Determine plane and polygon extraction from point clouds.
    alpha: 0.0 # must be set to 0.0 if using lmax
    lmax: 0.15 # maximum distance between points in plane for spatial connection
    z_thresh: 0.05 # enforce point to plane distance constraints during region growing.
    norm_thresh: 0.96 # Not used, set to the same as norm_thresh_min. Will deprecate later.
    norm_thresh_min: 0.96 # triangles must have a minimum amount of planarity.
    min_hole_vertices: 4 # minimum number of vertices in a hole to return
    min_triangles: 200 # minimum number of triangles needed to make a plane
fastga: # Parameters used for dominant plane normal estimation
    level: 4 # refinement level of the gaussian accumulator
    down_sample_fraction: 0.20 # only use X% of triangle normals from mesh for integration, lower the faster
    find_peaks_kwargs: # peak detection arguments
        threshold_abs: 50 # [0-255], minimum value of normalized histogram of S2 to be a peak
        min_distance: 1 # 1 = 3X3 kernel for peak detector. I recommend to not change
        exclude_border: true
        indices: false # must return mask
    cluster_kwargs: # Agglomerative hierarchal clustering
        t: 0.28 # min distance in 3D space of peaks (surface normals on sphere) before merging
        criterion: "distance"
    average_filter: # A merge group must have at least x% of value in all of histogram, this doesn't have much meaning and will probably be deprecated
        min_total_weight: 0.1
polygon:
    postprocess: # post processing of polygons returned from polylidar for ground/obstacle identification
        filter: # obstacles must have these characteristics
            hole_area:
                min: 0.05 # m^2
                max: 80.0 # m^2
            hole_vertices:
                min: 4
            plane_area:
                min: 0.1 # m^2
                max: 400
        # These parameters correspond to Shapely polygon geometry operations
        positive_buffer: 0.02 # m, Positively expand polygon.  Fills in small holes
        negative_buffer: 0.05 # m, Negative buffer to polygon. Expands holes and constricts outer hull of polygon
        simplify: 0.05 # m, simplify edges of polygon
polylabel:
    precision: 0.05

single_scan:
    command_frame: "ned" # 'body' or 'ned'
# Defining Fixed Homogenous Transformations
# Everything is in relation to the body frame of the drone
# Origin: Center of drone but at ground level, where landing gear touches ground.
# Axes: NED, X-Forward, Y-Right, Z-Down
frames:
    # The t265_sensor_mount origin is near center of the 265 camera. It keeps the same NED frame as the body for simplicity.  X-Forward, Y-Right, Z-Down
    t265_sensor_mount:
        #translation [0.5, 0.0, -0.5] # Example: this is saying the t265 is 0.5 meters to the right and 0.5 up from drone origin 
        translation: [0.0, 0.0, 0] # TODO UPDATE 
        rotation: # Theses rotations are defined from the drone frame to the sensor mount frame
            roll: 0.0
            pitch: 0.0  # TODO UPDATE
            yaw: 0.0
    # This transform represents the **internal** sensor coordinate frame of the t265
    # Its axes are Y-UP, Z-Back, X-Right (virtual reality headset standard axes frames, ohh Intel....)
    t265_sensor_axes:
        translation: [0.0, 0.0, 0.0] # leave at 0
        rotation: [ # x -> y, y -> -z  z -> -x # leave as is
        [0,  0, -1],
        [1,  0, 0],
        [0, -1, 0]
        ]
    # The l515_sensor_mount origin is near center of the l515 camera. It keeps the same NED frame as the body for simplicity.  X-Forward, Y-Right, Z-Down
    l515_sensor_mount:
        #translation [0.5, 0.0, -0.5] # Example: this is saying the l515 is 0.5 meters to the right and 0.5 up from drone origin 
        translation: [-0.07, 0.0, 0] # TODO UPDATE 
        rotation:   # Theses rotations are defined from the drone frame to the sensor mount frame
            roll: 0.0          
            pitch: -90.0  # TODO UPDATE, NEGATIVE MEANS THE CAMERA IS POINTING DOWNWARD
            yaw: 0.0
    # This transform represents the **internal** sensor coordinate frame of the l515
    # Its axes standard camera frame: Z-Forward, X-Right, Y-Down
    l515_sensor_axes:
        translation: [0.0, 0.0, 0.0] # leave at 0
        rotation: [ #  x -> y, y -> z, z -> x # leave as is
        [0, 0, 1],
        [1, 0, 0],
        [0, 1, 0]
      ]

publish:
    landing_message:
        active: true
        rate: 1
    single_scan: # rgbd_landing_message and touchdown message
        active: true
        rate: 3
    mesh_and_touchdown_message: # rgbd_landing_message and touchdown message
        active: true
    
    
    
    
# If the t265 and the l515 are rigidly attached to a backplate then:
#   1. The sensor mount_rotations will be identical!
#   2. Only the translations would marginally change

# If the t265 and L515 are NOT rigidly attached
#    1. The rotation and translation will be greatly decoupled